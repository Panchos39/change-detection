{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import GoogleV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocater = GoogleV3(api_key='AIzaSyDwaYFWNTiA-KbVbgPuXHrmE9UhODolw_k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = open('../../../datasets/change_detection_init_cities.list', 'r')\n",
    "cities = fin.read().split('\\n')\n",
    "fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_lat_long = []\n",
    "for city in cities[:-1]:\n",
    "#     print (city)\n",
    "    location = geolocater.geocode(city)\n",
    "    city_lat_long.append([city, location.latitude, location.longitude])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp -r gs://granular-ai/auth_files/granular-ai-b872e1ef7805.json /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client.from_service_account_json('/tmp/granular-ai-b872e1ef7805.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_tile_ids = []\n",
    "for city in city_lat_long:\n",
    "    city_name = city[0]\n",
    "    lat = city[1]\n",
    "    lon = city[2]\n",
    "    \n",
    "    query_str = (\n",
    "            'SELECT mgrs_tile FROM `bigquery-public-data.cloud_storage_geo_index.sentinel_2_index` ' + \n",
    "            'WHERE north_lat > ' + str(lat) + ' AND south_lat < ' + str(lat) + \n",
    "            ' AND west_lon < ' + str(lon) + ' AND east_lon > ' + str(lon) + \n",
    "            ' GROUP BY mgrs_tile' )\n",
    "\n",
    "#     print (query_str)\n",
    "    query_job = client.query(query_str)\n",
    "    iterator = query_job.result(timeout=30)\n",
    "\n",
    "    tile_ids = []\n",
    "    for it in iterator:\n",
    "        tile_ids.append(it['mgrs_tile'])\n",
    "    \n",
    "#     print (tile_ids)\n",
    "    city_tile_ids.append([city_name, tile_ids])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {}\n",
    "\n",
    "for city in city_tile_ids:\n",
    "    city_name = city[0]\n",
    "    tile_ids = city[1]\n",
    "    \n",
    "    tid_metas = {}\n",
    "    for tid in tile_ids:\n",
    "        query_str = (\n",
    "                'SELECT * FROM `bigquery-public-data.cloud_storage_geo_index.sentinel_2_index` ' +\n",
    "                'WHERE cloud_cover < \"1.0\" AND mgrs_tile=\"' + tid + '\" AND total_size > 500000000')\n",
    "        \n",
    "        query_job = client.query(query_str)\n",
    "        iterator = query_job.result(timeout=30)\n",
    "        \n",
    "        metas = []\n",
    "        for it in iterator:\n",
    "            metas.append([it['base_url'], it['sensing_time']])\n",
    "        \n",
    "        tid_metas[tid] = metas\n",
    "    metadata[city_name] = tid_metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = open('../../../datasets/100_cities_metadata.json','w')\n",
    "json.dump(metadata, fout)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singapore 48NUG\n",
      "Johor Bahru 48NUG\n"
     ]
    }
   ],
   "source": [
    "inference_metadata = {}\n",
    "\n",
    "tot_tiles = 0\n",
    "for city in metadata.keys():\n",
    "    inference_tiles_meta = {}\n",
    "    for tile_id in metadata[city].keys():\n",
    "        tile_metadata = metadata[city][tile_id]\n",
    "        if len(tile_metadata) > 0:\n",
    "            tile_metadata.sort(key=lambda x: x[1])\n",
    "            first_date = tile_metadata[0]\n",
    "            last_date = tile_metadata[-1]\n",
    "            inference_tiles_meta[tile_id] = [first_date[0], last_date[0]]\n",
    "            tot_tiles += 1\n",
    "        else:\n",
    "            print (city, tile_id)\n",
    "    inference_metadata[city] = inference_tiles_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = open('../../../datasets/100_cities_inference_metadata.json','w')\n",
    "json.dump(inference_metadata, fout)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = open('../../../datasets/100_cities_inference_tiles.sh','w')\n",
    "done = {}\n",
    "for city in inference_metadata.keys():\n",
    "    tile_ids = inference_metadata[city]\n",
    "    for tile_id in tile_ids.keys():\n",
    "        if tile_ids[tile_id][0] not in done:\n",
    "            fout.write('gsutil -m cp -r ' + tile_ids[tile_id][0] + ' . \\n')\n",
    "            done[tile_ids[tile_id][0]] = 1\n",
    "        if tile_ids[tile_id][1] not in done:\n",
    "            fout.write('gsutil -m cp -r ' + tile_ids[tile_id][1] + ' . \\n')\n",
    "            done[tile_ids[tile_id][1]] = 1\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = {}\n",
    "pairs = []\n",
    "for city in inference_metadata.keys():\n",
    "    tile_ids = inference_metadata[city]\n",
    "    for tile_id in tile_ids.keys():\n",
    "        if tile_ids[tile_id][0] + '_' + tile_ids[tile_id][1] not in done:\n",
    "            done[tile_ids[tile_id][0] + '_' + tile_ids[tile_id][1]] = 1\n",
    "            pairs.append(tile_ids[tile_id] + [tile_id])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = open('../../../datasets/100_cities_distinct_pairs.csv','w')\n",
    "w = csv.writer(fout)\n",
    "\n",
    "for pair in pairs:\n",
    "    safe1 = pair[0].split('/')[-1]\n",
    "    d1 = safe1.split('_')[2]\n",
    "    safe2 = pair[1].split('/')[-1]\n",
    "    d2 = safe2.split('_')[2]\n",
    "    w.writerow([d1, safe1, d2, safe2, pair[-1]])\n",
    "    \n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = open('../../../datasets/100_cities_inferece_analysis.csv','w')\n",
    "w = csv.writer(fout)\n",
    "\n",
    "tid_d1d2_map = {}\n",
    "for pair in pairs:\n",
    "    safe1 = pair[0].split('/')[-1]\n",
    "    d1 = safe1.split('_')[2].split('T')[0]\n",
    "    safe2 = pair[1].split('/')[-1]\n",
    "    d2 = safe2.split('_')[2].split('T')[0]\n",
    "#     w.writerow([pair[-1], d1, d2])\n",
    "    tid_d1d2_map[pair[-1]] = [d1, d2]\n",
    "    \n",
    "for city in inference_metadata.keys():\n",
    "    for tid in inference_metadata[city]:\n",
    "        w.writerow([city, tid] + tid_d1d2_map[tid])\n",
    "\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
